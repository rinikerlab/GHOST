{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Optimize the decision threshold of binary classifiers using GHOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import the ghostml library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import ghostml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Function to calculate classification metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def calc_metrics(labels_test, test_preds = None, test_probs = None, threshold = 0.5):\n",
    "    if test_preds is None and test_probs is None:\n",
    "        return print(\"ERROR: specify test_preds or test_probs\")\n",
    "    if test_preds is not None:\n",
    "        scores = list(test_preds)\n",
    "        auc = metrics.roc_auc_score(labels_test, scores)\n",
    "    if test_probs is not None:\n",
    "        scores = [1 if x>=threshold else 0 for x in test_probs]\n",
    "        auc = metrics.roc_auc_score(labels_test, test_probs)\n",
    "    kappa = metrics.cohen_kappa_score(labels_test,scores)\n",
    "    confusion = metrics.confusion_matrix(labels_test,scores, labels=list(set(labels_test)))\n",
    "    print('thresh: %.2f, kappa: %.3f, AUC test-set: %.3f'%(threshold, kappa, auc))\n",
    "    print(confusion)\n",
    "    print(metrics.classification_report(labels_test,scores))\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Example 1: Optimize the classification threshold of binary classifiers returning probability estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a binary imbalanced classification problem, with 80% zeros and 20% ones.\n",
    "X, y = make_classification(n_samples=1000, n_features=20,\n",
    "                           n_informative=14, n_redundant=0,\n",
    "                           random_state=0, shuffle=False, weights = [0.8, 0.2])\n",
    "\n",
    "# Train - test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state=0)\n",
    "\n",
    "# Train a RF classifier\n",
    "cls = RandomForestClassifier(max_depth=6, oob_score=True)\n",
    "cls.fit(X_train, y_train)\n",
    "\n",
    "# Get prediction probabilities for the test set\n",
    "test_probs = cls.predict_proba(X_test)[:,1] \n",
    "\n",
    "# Print confusion matrix and classification metrics\n",
    "calc_metrics(y_test, test_probs = test_probs, threshold = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Optimize the decision threshold using GHOST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use the Cohen's Kappa as optimization metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# extract the positive prediction probabilities for the training set from the trained RF model\n",
    "train_probs = cls.predict_proba(X_train)[:,1]\n",
    "\n",
    "# optmize the threshold \n",
    "thresholds = np.round(np.arange(0.05,0.55,0.05),2)\n",
    "threshold1 = ghostml.optimize_threshold_from_predictions(y_train, train_probs, thresholds, ThOpt_metrics = 'Kappa') \n",
    "\n",
    "# Print confusion matrix and classification metrics\n",
    "calc_metrics(y_test, test_probs = test_probs, threshold = threshold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Example 2: Optimize the hyperplane position of hyperplane based classifiers (e.g. SVM, Ridge)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a binary imbalanced classification problem, with 80% zeros and 20% ones.\n",
    "X, y = make_classification(n_samples=1000, n_features=20,\n",
    "                           n_informative=14, n_redundant=0,\n",
    "                           random_state=0, shuffle=False, weights = [0.9, 0.1])\n",
    "\n",
    "# Train - test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state=0)\n",
    "\n",
    "# Train a linear SVC classifier\n",
    "cls = make_pipeline(StandardScaler(), LinearSVC())\n",
    "cls.fit(X_train, y_train)\n",
    "cls_model = cls['linearsvc']\n",
    "\n",
    "# Get prediction probabilities for the test set\n",
    "test_preds = cls.predict(X_test)\n",
    "\n",
    "# Print confusion matrix and classification metrics\n",
    "calc_metrics(y_test, test_preds = test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Optimize the hyperplane position using GHOST**\n",
    "\n",
    "Use the MCC as optimization metric.\n",
    "\n",
    "With `average='curve'`, GHOST calculates the median classification metric per hyperplane shift over the N_subsets\n",
    "            and returns the hyperplane shift that optimizes the median optimization curve."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# extract the decision function values for the training set.\n",
    "# If decision_function_shape=’ovo’, these values are proportional to the distance of the samples to the separating hyperplane.\n",
    "# If the exact distances are required, divide the function values by the norm of the weight vector (coef_)\n",
    "train_distances = cls_model.decision_function(X_train)\n",
    "\n",
    "# optimize the hyperplane shift using the Matthews correlation coefficient as optimization metric\n",
    "hyperplane_shift = ghostml.svm_othr_from_predictions(y_train, train_distances, ThOpt_metrics = 'mcc', average='curve',\n",
    "                                                     plot_optimization_curve=True, figure_folder='.', figure_basename='curve_average', N_subsets=300\n",
    "                                                     )\n",
    "\n",
    "# shift the hyperplane and recalculate the test predictions\n",
    "scores_test = cls_model.decision_function(X_test) + hyperplane_shift\n",
    "test_preds_new = [1 if x>=0 else 0 for x in scores_test]\n",
    "\n",
    "# Print confusion matrix and classification metrics\n",
    "calc_metrics(y_test, test_preds = test_preds_new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With `average='threshold'`, GHOST calculates the hyperplane shift for every subset\n",
    "            and returns the median optimal hyperplane shift over the N_subsets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# optimize the hyperplane shift using the Matthews correlation coefficient as optimization metric\n",
    "hyperplane_shift = ghostml.svm_othr_from_predictions(y_train, train_distances, ThOpt_metrics = 'mcc', average='threshold',\n",
    "                                                     plot_optimization_curve=True, figure_folder='.', figure_basename='threshold_average', N_subsets=300\n",
    "                                                     )\n",
    "\n",
    "# shift the hyperplane and recalculate the test predictions\n",
    "scores_test = cls_model.decision_function(X_test) + hyperplane_shift\n",
    "test_preds_new = [1 if x>=0 else 0 for x in scores_test]\n",
    "\n",
    "# Print confusion matrix and classification metrics\n",
    "calc_metrics(y_test, test_preds = test_preds_new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}